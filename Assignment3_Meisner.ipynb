{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Non Improved CIFAR-10 Deeper Network\n",
    "\n",
    "from keras.datasets import cifar10\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import SGD, Adam, RMSprop\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "IMG_CHANNELS = 3\n",
    "IMG_ROWS = 32\n",
    "IMG_COLS = 32\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "NB_EPOCH = 20\n",
    "NB_CLASSES = 10\n",
    "VERBOSE = 1\n",
    "VALIDATION_SPLIT = 0.2\n",
    "OPTIM = RMSprop()\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('X_train shape[0]', 'train samples')\n",
    "print('X_train shape[0]', 'test samples')\n",
    "\n",
    "Y_train = np_utils.to_categorical(y_train, NB_CLASSES)\n",
    "Y_test = np_utils.to_categorical(y_test, NB_CLASSES)\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=(IMG_ROWS, IMG_COLS, IMG_CHANNELS)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(NB_CLASSES))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=OPTIM,\n",
    "             metrics=['accuracy'])\n",
    "model.fit(X_train, Y_train, batch_size=BATCH_SIZE,\n",
    "         epochs=NB_EPOCH, validation_split=VALIDATION_SPLIT,\n",
    "         verbose=VERBOSE)\n",
    "score = model.evaluate(X_test, Y_test,\n",
    "                      batch_size=BATCH_SIZE, verbose=VERBOSE)\n",
    "print(\"Test score:\", score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "model_json = model.to_json()\n",
    "open('cifar10_architecture.json', 'w').write(model_json)\n",
    "model.save_weights('cifar10_weights.h5', overwrite=True)\n",
    "          \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmenting training set images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:41: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras.pre..., epochs=20, verbose=1, steps_per_epoch=390)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "390/390 [==============================] - 67s 173ms/step - loss: 2.3107 - accuracy: 0.0984\n",
      "Epoch 2/20\n",
      "390/390 [==============================] - 68s 174ms/step - loss: 2.3117 - accuracy: 0.0981\n",
      "Epoch 3/20\n",
      "390/390 [==============================] - 71s 182ms/step - loss: 2.3116 - accuracy: 0.0986\n",
      "Epoch 4/20\n",
      "390/390 [==============================] - 78s 199ms/step - loss: 2.3087 - accuracy: 0.0970\n",
      "Epoch 5/20\n",
      "390/390 [==============================] - 71s 181ms/step - loss: 2.3056 - accuracy: 0.0994\n",
      "Epoch 6/20\n",
      "390/390 [==============================] - 68s 173ms/step - loss: 2.3073 - accuracy: 0.0986\n",
      "Epoch 7/20\n",
      "390/390 [==============================] - 68s 175ms/step - loss: 2.3129 - accuracy: 0.0982\n",
      "Epoch 8/20\n",
      "390/390 [==============================] - 68s 173ms/step - loss: 2.3039 - accuracy: 0.0973\n",
      "Epoch 9/20\n",
      "390/390 [==============================] - 68s 174ms/step - loss: 2.3036 - accuracy: 0.0987\n",
      "Epoch 10/20\n",
      "390/390 [==============================] - 70s 179ms/step - loss: 2.3061 - accuracy: 0.0955\n",
      "Epoch 11/20\n",
      "390/390 [==============================] - 70s 179ms/step - loss: 2.3079 - accuracy: 0.0980\n",
      "Epoch 12/20\n",
      "390/390 [==============================] - 69s 176ms/step - loss: 2.3033 - accuracy: 0.0988\n",
      "Epoch 13/20\n",
      "390/390 [==============================] - 68s 175ms/step - loss: 2.3065 - accuracy: 0.0967\n",
      "Epoch 14/20\n",
      "390/390 [==============================] - 69s 177ms/step - loss: 2.3091 - accuracy: 0.0972\n",
      "Epoch 15/20\n",
      "390/390 [==============================] - 69s 178ms/step - loss: 2.3157 - accuracy: 0.0978\n",
      "Epoch 16/20\n",
      "390/390 [==============================] - 68s 175ms/step - loss: 2.3037 - accuracy: 0.0989\n",
      "Epoch 17/20\n",
      "390/390 [==============================] - 68s 175ms/step - loss: 2.3069 - accuracy: 0.0989s - loss: 2.3070 - accu\n",
      "Epoch 18/20\n",
      "390/390 [==============================] - 69s 176ms/step - loss: 2.3100 - accuracy: 0.0962\n",
      "Epoch 19/20\n",
      "390/390 [==============================] - 68s 175ms/step - loss: 2.3077 - accuracy: 0.0970\n",
      "Epoch 20/20\n",
      "390/390 [==============================] - 68s 175ms/step - loss: 2.3064 - accuracy: 0.0985\n",
      "10000/10000 [==============================] - 6s 557us/step\n",
      "Test score: 2.3023690757751463\n",
      "Test accuracy: 0.10010000318288803\n"
     ]
    }
   ],
   "source": [
    "#Improving CIFAR-10 performance with data augmentation\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.datasets import cifar10\n",
    "import numpy as np\n",
    "NUM_TO_AUGMENT=5\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "\n",
    "print(\"Augmenting training set images...\")\n",
    "datagen = ImageDataGenerator(\n",
    "rotation_range=40,\n",
    "width_shift_range=0.2,\n",
    "height_shift_range=0.2,\n",
    "zoom_range=0.2,\n",
    "horizontal_flip=True,\n",
    "fill_mode='nearest')\n",
    "\n",
    "xtas, ytas = [], []\n",
    "for i in range(X_train.shape[0]):\n",
    "    num_aug = 0\n",
    "    x = X_train[i]\n",
    "    x = x.reshape((1,) + x.shape)\n",
    "    \n",
    "    for x_aug in datagen.flow(x, batch_size=1,\n",
    "                              #save_to_dir='preview',\n",
    "                              #save_prefix='cifar',\n",
    "                              #save_format='jpeg'):\n",
    "                             ):\n",
    "        \n",
    "        if num_aug >= NUM_TO_AUGMENT:\n",
    "            break\n",
    "        xtas.append(x_aug[0])\n",
    "        num_aug += 1\n",
    "            \n",
    "datagen.fit(X_train)\n",
    "\n",
    "history = model.fit_generator(datagen.flow(\n",
    "    X_train, Y_train,\n",
    "    batch_size=BATCH_SIZE),\n",
    "                              samples_per_epoch=X_train.shape[0],\n",
    "                              epochs=NB_EPOCH, verbose=VERBOSE)\n",
    "score = model.evaluate(X_test, Y_test, batch_size=BATCH_SIZE, verbose=VERBOSE)\n",
    "print(\"Test score:\", score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explain how this algorithm could result in ethical and privacy concerns if it were trained on different sets of images.\n",
    "\n",
    "When it comes to the safety of people traversing the internet, people do not usually think of the chance that someone may use Artificial Intelligence to clone the likeness of their face. With the evolution of the internet, social media, and the general understanding of technology every day people are beginning to cultivate the power of Artificial Intelligence, using it almost as normally as a phone.\n",
    "\n",
    "We are not quite in the picture I am painting just yet, but we are on our way there, as normal people that have access to the internet are easily able to research how to create a surface level version of this technology, or even find an app on their phone to do it for them.\n",
    "\n",
    "\"The first attempt of deepfake creation was FakeApp, developed by a Reddit user using autoencoder-decoder pairing structure. In that method, the autoencoder extracts latent features of face images and the decoder is used to reconstruct the face images.\" (Nguyen et al., 2022)\n",
    "\n",
    "Essentially, the extraction of latent features simply put can be deduced to two variables that may contribute to the creation of a singular attribute. In other words, if someone has a big nose, there maybe pixels within the resolution of the image to support that, and when cross referenced against other pictures of people with big noses, there maybe a pattern there that the AI is able to understand, and attach to in order to create, or replicate rather, other big noses amongst other attributes in an image. This is a farily simple concept to understand, but one you do not need to fully grasp to follow any type of tutorial, or use any type of application that makes it easy to feed in images of somebody you know in order to get back a specific type of picture you may want. \n",
    "\n",
    "Upon googling FakeApp you are easily able to find the website which has a wonderful installation guide, in addition to a tutorial and many other resources that could help someone understand how to use the tool and break into the world of Artificial Intelligence. Most importantly, this website has a page of ethics. I think that this is the perfect example of responsible software engineering, as this is a key example of the type of work you could expect to see, and interact with, as it is all about the user and the foundational building point left for others to use, and learn from.\n",
    "\n",
    "One breech of ethicality which is further explained on this site is the creation of non-consensaul porn. There are societies of addicts created to share, and create these pictures. Additionally, these types of pictures can spread quickly meaning that there is truly no limit in which someones privacy can be violated, and even defaming them to a point in which could be humiliating dependent on the picture. \n",
    "\n",
    "The type of trauma that can stem from these events can result in tragedy. \"Due to this, most people who have heard of deepfakes now associate them with non-consensual pornography, which is ultimately the reason why websites like Twitter, Reddit and even Pornhub banned them from their platforms.\" (Zucconi, 2018)\n",
    "\n",
    "\n",
    "Citations:\n",
    "\n",
    "Nguyen, T.T., Nguyen, Q. V. H., Nguyen, D. T., Nguyen, D. T., Huynh-The, T., Nahavandi, S., Nguyen, T. T., Pham, Q.-V., & Nguyen, C. M. (2022, August 11). Deep learning for deepfakes creation and detection: A survey - arxiv. arxiv.org. Retrieved November 12, 2022, from https://arxiv.org/pdf/1909.11573.pdf\n",
    "\n",
    "Zucconi, A. (2018, March 21). The ethics of Deepfakes. Alan Zucconi. Retrieved November 11, 2022, from https://www.alanzucconi.com/2018/03/14/the-ethics-of-deepfakes/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
